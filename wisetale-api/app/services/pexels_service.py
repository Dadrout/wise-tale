"""
Pexels API service for image search and management
"""
import os
import requests
import json
from typing import List, Dict, Optional
import hashlib
import re
from app.core.config import settings

class PexelsService:
    """
    Pexels API Service for finding fallback images.
    """
    def __init__(self):
        self.base_url = "https://api.pexels.com/v1"
        self.api_key = settings.PEXELS_API_KEY
        if not self.api_key:
            print("‚ö†Ô∏è PEXELS_API_KEY not found. Pexels API will not be available.")

    def _get_headers(self):
        if not self.api_key:
            return {}
        return {
            "Authorization": self.api_key
        }

    def extract_keywords_from_story(self, story_text: str, subject: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
        –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        """
        keywords = []
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç markdown –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        clean_text = story_text.replace('**', '').replace('###', '').replace('---', '')
        clean_text = clean_text.replace('##', '').replace('#', '').replace('*', '').replace('_', '')
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
        if subject.lower() == "history":
            historical_keywords = [
                # –û–±—â–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                'empire', 'kingdom', 'civilization', 'ancient', 'medieval', 'renaissance',
                'war', 'battle', 'revolution', 'conquest', 'dynasty', 'emperor', 'king', 'queen',
                'castle', 'fortress', 'palace', 'cathedral', 'temple', 'monument',
                'army', 'soldiers', 'weapons', 'armor', 'sword', 'shield',
                'artifact', 'manuscript', 'document', 'scroll', 'ruins',
                
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
                'BC', 'AD', 'century', 'era', 'age', 'period',
                
                # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏ —Ä–æ–ª–∏
                'pharaoh', 'caesar', 'general', 'philosopher', 'scholar', 'priest',
                
                # –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                'rome', 'egypt', 'greece', 'constantinople', 'jerusalem', 'babylon',
                'mediterranean', 'nile', 'tiber', 'danube',
                
                # –ö—É–ª—å—Ç—É—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                'culture', 'religion', 'mythology', 'gods', 'goddess', 'ritual',
                'art', 'sculpture', 'painting', 'architecture', 'column'
            ]
            
            # –ò—â–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ
            for keyword in historical_keywords:
                if keyword.lower() in clean_text.lower():
                    keywords.append(keyword)
        
        elif subject.lower() == "geography":
            geo_keywords = [
                'mountain', 'river', 'ocean', 'sea', 'desert', 'forest', 'valley', 'canyon',
                'continent', 'island', 'peninsula', 'plateau', 'plain', 'coast', 'beach',
                'volcano', 'glacier', 'lake', 'waterfall', 'cave', 'cliff',
                'city', 'capital', 'country', 'nation', 'border', 'region',
                'climate', 'weather', 'landscape', 'terrain', 'natural', 'environment'
            ]
            
            for keyword in geo_keywords:
                if keyword.lower() in clean_text.lower():
                    keywords.append(keyword)
        
        elif subject.lower() == "philosophy":
            phil_keywords = [
                'wisdom', 'knowledge', 'truth', 'ethics', 'morality', 'logic', 'reason',
                'thought', 'mind', 'consciousness', 'existence', 'reality', 'universe',
                'book', 'library', 'scroll', 'manuscript', 'writing', 'text',
                'scholar', 'thinker', 'sage', 'student', 'teacher', 'academy',
                'meditation', 'contemplation', 'reflection', 'debate', 'discussion'
            ]
            
            for keyword in phil_keywords:
                if keyword.lower() in clean_text.lower():
                    keywords.append(keyword)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ (–Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã)
        proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', clean_text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞
        common_words = {'The', 'This', 'That', 'These', 'Those', 'When', 'Where', 'Why', 'How', 'What', 'Who'}
        proper_nouns = [noun for noun in proper_nouns if noun not in common_words and len(noun) > 2]
        
        keywords.extend(proper_nouns[:5])  # –ë–µ—Ä–µ–º –¥–æ 5 –∏–º–µ–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–∂–Ω—ã–µ —á–∏—Å–ª–∞ (–≥–æ–¥—ã, –≤–µ–∫–∞)
        years = re.findall(r'\b(?:1\d{3}|2\d{3})\b', clean_text)  # 1000-2999
        centuries = re.findall(r'\b\d{1,2}(?:st|nd|rd|th)\s+century\b', clean_text.lower())
        
        if years:
            keywords.extend([f"year {year}" for year in years[:2]])
        if centuries:
            keywords.extend(centuries[:2])
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        return list(set(keywords))

    async def search_images(self, query: str, per_page: int = 10, orientation: str = "landscape") -> List[Dict]:
        """
        Search for images on Pexels
        Args:
            query: Search term (e.g., "French Revolution", "Ancient Egypt")
            per_page: Number of images to return (max 80)
            orientation: "landscape", "portrait", or "square"
        Returns:
            List of image data dictionaries
        """
        params = {
            "query": query,
            "per_page": min(per_page, 80),  # Pexels max is 80
            "orientation": orientation,
            "size": "medium"
        }
        
        try:
            response = requests.get(
                f"{self.base_url}/search",
                headers=self._get_headers(),
                params=params,
                timeout=30
            )
            response.raise_for_status()
            
            data = response.json()
            photos = data.get("photos", [])
            
            # Process images for our use case
            processed_images = []
            for photo in photos:
                processed_images.append({
                    "id": photo["id"],
                    "url": photo["src"]["large"],
                    "medium_url": photo["src"]["medium"],
                    "small_url": photo["src"]["small"],
                    "photographer": photo["photographer"],
                    "photographer_url": photo["photographer_url"],
                    "alt": photo.get("alt", query),
                    "width": photo["width"],
                    "height": photo["height"]
                })
            
            return processed_images
            
        except requests.RequestException as e:
            print(f"Pexels API error: {str(e)}")
            return []
    
    async def search_curated_images(self, per_page: int = 10) -> List[Dict]:
        """Get curated photos from Pexels"""
        params = {"per_page": min(per_page, 80)}
        
        try:
            response = requests.get(
                f"{self.base_url}/curated",
                headers=self._get_headers(),
                params=params,
                timeout=30
            )
            response.raise_for_status()
            
            data = response.json()
            photos = data.get("photos", [])
            
            processed_images = []
            for photo in photos:
                processed_images.append({
                    "id": photo["id"],
                    "url": photo["src"]["large"],
                    "medium_url": photo["src"]["medium"],
                    "small_url": photo["src"]["small"],
                    "photographer": photo["photographer"],
                    "photographer_url": photo["photographer_url"],
                    "alt": photo.get("alt", "Curated photo"),
                    "width": photo["width"],
                    "height": photo["height"]
                })
            
            return processed_images
            
        except requests.RequestException as e:
            print(f"Pexels API error: {str(e)}")
            return []
    
    def get_smart_search_terms(self, topic: str, subject: str) -> List[str]:
        """
        Generate multiple search terms for better image diversity
        """
        base_terms = [topic.lower()]
        
        # Subject-specific terms
        if subject.lower() == "history":
            additional_terms = [
                f"{topic} historical",
                f"{topic} ancient",
                f"{topic} civilization",
                f"{topic} culture",
                "historical artifacts",
                "old documents",
                "antique objects"
            ]
        elif subject.lower() == "geography":
            additional_terms = [
                f"{topic} landscape",
                f"{topic} nature",
                f"{topic} geography",
                f"{topic} map",
                "world map",
                "mountains",
                "rivers",
                "cities"
            ]
        elif subject.lower() == "philosophy":
            additional_terms = [
                f"{topic} philosophy",
                f"{topic} thinking",
                "books",
                "library",
                "wisdom",
                "meditation",
                "contemplation",
                "ancient philosophy"
            ]
        else:
            additional_terms = [f"{topic} education", f"{topic} learning"]
        
        return base_terms + additional_terms[:4]  # Limit to 5 total terms
    
    def get_enhanced_search_terms(self, topic: str, subject: str, story_text: Optional[str] = None) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–º—ã, –ø—Ä–µ–¥–º–µ—Ç–∞ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
        """
        search_terms = []
        
        # –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        base_terms = [topic.lower()]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –æ–Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞
        if story_text:
            story_keywords = self.extract_keywords_from_story(story_text, subject)
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ç–µ–º—É —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            for keyword in story_keywords[:8]:  # –ë–µ—Ä–µ–º —Ç–æ–ø-8 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                search_terms.append(f"{topic} {keyword}")
                search_terms.append(keyword)
        
        # –ü—Ä–µ–¥–º–µ—Ç–Ω–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        if subject.lower() == "history":
            additional_terms = [
                f"{topic} historical",
                f"{topic} ancient",
                f"{topic} medieval",
                f"{topic} civilization",
                f"{topic} culture",
                f"{topic} empire",
                f"{topic} archaeological",
                "historical artifacts",
                "ancient architecture",
                "historical documents",
                "medieval art",
                "ancient sculptures",
                "historical paintings",
                "old manuscripts",
                "antique objects",
                "historical sites",
                "ancient ruins"
            ]
        elif subject.lower() == "geography":
            additional_terms = [
                f"{topic} landscape",
                f"{topic} nature",
                f"{topic} geography",
                f"{topic} terrain",
                f"{topic} environment",
                f"{topic} map",
                f"{topic} satellite",
                "world map",
                "topographic map",
                "mountains",
                "rivers",
                "forests",
                "cities",
                "natural landscape",
                "aerial view",
                "satellite image"
            ]
        elif subject.lower() == "philosophy":
            additional_terms = [
                f"{topic} philosophy",
                f"{topic} thinking",
                f"{topic} wisdom",
                f"{topic} scholar",
                "ancient philosophy",
                "philosophical books",
                "library",
                "wisdom",
                "meditation",
                "contemplation",
                "ancient texts",
                "scrolls",
                "philosophical art",
                "thinking statue",
                "ancient library"
            ]
        else:
            additional_terms = [f"{topic} education", f"{topic} learning", f"{topic} academic"]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–µ—Ä–º–∏–Ω—ã
        all_terms = base_terms + search_terms + additional_terms
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        unique_terms = []
        seen = set()
        for term in all_terms:
            if term.lower() not in seen and len(term) > 2:
                unique_terms.append(term)
                seen.add(term.lower())
        
        return unique_terms[:15]  # –ú–∞–∫—Å–∏–º—É–º 15 –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

    async def get_diverse_images(self, topic: str, subject: str, count: int = 8, story_text: Optional[str] = None) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –Ω–∞–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        –∏ –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
        """
        search_terms = self.get_enhanced_search_terms(topic, subject, story_text)
        all_images = []
        
        print(f"üîç Searching with {len(search_terms)} enhanced terms for '{topic}' in {subject}")
        
        # –ò—â–µ–º –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        images_per_search = max(2, count // len(search_terms) + 1)
        
        for i, term in enumerate(search_terms):
            try:
                images = await self.search_images(term, per_page=images_per_search)
                all_images.extend(images)
                print(f"  üì∏ Term '{term}': found {len(images)} images")
                
                # –ï—Å–ª–∏ —Å–æ–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–æ–∏—Å–∫
                if len(all_images) >= count * 2:  # –°–æ–±–∏—Ä–∞–µ–º –±–æ–ª—å—à–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤—ã–±–æ—Ä–∞
                    break
                    
            except Exception as e:
                print(f"  ‚ùå Search failed for '{term}': {e}")
                continue
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ ID –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ
        seen_ids = set()
        unique_images = []
        
        for image in all_images:
            if image["id"] not in seen_ids:
                seen_ids.add(image["id"])
                unique_images.append(image)
        
        print(f"üìä Total unique images found: {len(unique_images)}, requested: {count}")
        
        # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –º–∞–ª–æ, –¥–æ–±–∞–≤–ª—è–µ–º fallback –ø–æ–∏—Å–∫–∏
        if len(unique_images) < count:
            fallback_terms = [
                f"{subject} education",
                f"{subject} learning", 
                "historical education" if subject == "history" else f"{subject} academic",
                "educational content"
            ]
            
            for term in fallback_terms:
                if len(unique_images) >= count:
                    break
                try:
                    fallback_images = await self.search_images(term, per_page=3)
                    for img in fallback_images:
                        if img["id"] not in seen_ids and len(unique_images) < count:
                            seen_ids.add(img["id"])
                            unique_images.append(img)
                except:
                    continue
        
        return unique_images[:count]

# Global instance
pexels_service = PexelsService() 